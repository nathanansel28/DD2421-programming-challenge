{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\natha\\AppData\\Local\\Temp\\ipykernel_12992\\783012097.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[bool_cols] = X_train[bool_cols].astype(int)\n",
      "C:\\Users\\natha\\AppData\\Local\\Temp\\ipykernel_12992\\783012097.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = le.fit_transform(X_train[col])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy: 0.6752 Â± 0.0157\n",
      "Submission file saved as submission.csv ðŸš€\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset (assuming train_raw and test_raw are available)\n",
    "train_raw = train_raw.copy()\n",
    "test_raw = test_raw.copy()\n",
    "\n",
    "# Select features and target\n",
    "features = [f\"x{i}\" for i in range(1, 14)]\n",
    "X_train = train_raw[features]\n",
    "y_train = train_raw['y']\n",
    "X_test = test_raw[features]  # 10,000 test data points for Kaggle submission\n",
    "\n",
    "# Encode categorical target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)  # Converts ['Anthropic', 'OpenAI', 'Mistral'] to [0, 1, 2]\n",
    "\n",
    "# Convert boolean columns to integers (if any)\n",
    "bool_cols = X_train.select_dtypes(include=['bool']).columns\n",
    "X_train[bool_cols] = X_train[bool_cols].astype(int)\n",
    "X_test[bool_cols] = X_test[bool_cols].astype(int)\n",
    "\n",
    "# Encode categorical features (if any)\n",
    "cat_cols = X_train.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    X_train[col] = le.fit_transform(X_train[col])\n",
    "    X_test[col] = le.transform(X_test[col])  # Apply the same encoding to test\n",
    "\n",
    "# XGBoost parameters\n",
    "params = {\n",
    "    \"objective\": \"multi:softmax\",  # Multiclass classification\n",
    "    \"num_class\": len(np.unique(y_train)),  # Number of classes\n",
    "    \"eval_metric\": \"mlogloss\",  # Multi-class log loss (good for Kaggle)\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"max_depth\": 6,\n",
    "    \"n_estimators\": 300,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "# K-Fold Cross Validation (Stratified)\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = []\n",
    "for train_idx, val_idx in kf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    # Train XGBoost\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Validate model\n",
    "    y_val_pred = model.predict(X_val_fold)\n",
    "    acc = accuracy_score(y_val_fold, y_val_pred)\n",
    "    cv_scores.append(acc)\n",
    "\n",
    "print(f\"Cross-validation accuracy: {np.mean(cv_scores):.4f} Â± {np.std(cv_scores):.4f}\")\n",
    "\n",
    "# Train final model on full training data\n",
    "final_model = xgb.XGBClassifier(**params)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "\n",
    "# Convert predictions back to original labels\n",
    "y_test_pred_labels = label_encoder.inverse_transform(y_test_pred)\n",
    "\n",
    "# Save for Kaggle submission\n",
    "submission = pd.DataFrame({\"id\": test_raw.index, \"y\": y_test_pred_labels})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Submission file saved as submission.csv ðŸš€\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

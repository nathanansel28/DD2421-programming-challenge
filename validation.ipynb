{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data import *\n",
    "from tools import train_kcv\n",
    "from ensemble import train_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_weights(final_results, n_top=5):\n",
    "    # Sort by mean_accuracy (top 5 accuracies)\n",
    "    top_5_accuracies = sorted(final_results, key=lambda x: x['mean_accuracy'], reverse=True)[:n_top]\n",
    "\n",
    "    # Sort by mean_log_loss (bottom 5 log-losses)\n",
    "    bottom_5_loglosses = sorted(final_results, key=lambda x: x['mean_log_loss'])[:n_top]\n",
    "\n",
    "    print(f\"Top {n_top} Accuracies:\")\n",
    "    for i, result in enumerate(top_5_accuracies, 1):\n",
    "        print(f\"{i}. Weights: {[round(float(w), 2) for w in result['weights']]} | \"\n",
    "              f\"Mean Accuracy: {result['mean_accuracy']:.3f} | \"\n",
    "              f\"Std Accuracy: {result['std_accuracy']:.3f} | \"\n",
    "              f\"Mean Log Loss: {result['mean_log_loss']:.3f} | \"\n",
    "              f\"Std Log Loss: {result['std_log_loss']:.3f}\")\n",
    "\n",
    "    print(f\"\\nBottom {n_top} Log Losses:\")\n",
    "    for i, result in enumerate(bottom_5_loglosses, 1):\n",
    "        print(f\"{i}. Weights: {[round(float(w), 2) for w in result['weights']]} | \"\n",
    "              f\"Mean Accuracy: {result['mean_accuracy']:.3f} | \"\n",
    "              f\"Std Accuracy: {result['std_accuracy']:.3f} | \"\n",
    "              f\"Mean Log Loss: {result['mean_log_loss']:.3f} | \"\n",
    "              f\"Std Log Loss: {result['std_log_loss']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Model trainings successful, proceeding to weight combination search...\n",
      "Weight combination search done.\n",
      "Top 100 Accuracies:\n",
      "1. Weights: [0.03, 0.03, 0.37, 0.57] | Mean Accuracy: 0.696 | Std Accuracy: 0.014 | Mean Log Loss: 0.718 | Std Log Loss: 0.009\n",
      "2. Weights: [0.03, 0.07, 0.37, 0.53] | Mean Accuracy: 0.696 | Std Accuracy: 0.015 | Mean Log Loss: 0.717 | Std Log Loss: 0.009\n",
      "3. Weights: [0.03, 0.13, 0.37, 0.47] | Mean Accuracy: 0.696 | Std Accuracy: 0.012 | Mean Log Loss: 0.716 | Std Log Loss: 0.009\n",
      "4. Weights: [0.0, 0.1, 0.33, 0.57] | Mean Accuracy: 0.696 | Std Accuracy: 0.013 | Mean Log Loss: 0.720 | Std Log Loss: 0.009\n",
      "5. Weights: [0.07, 0.13, 0.37, 0.43] | Mean Accuracy: 0.696 | Std Accuracy: 0.012 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "6. Weights: [0.1, 0.13, 0.37, 0.4] | Mean Accuracy: 0.696 | Std Accuracy: 0.012 | Mean Log Loss: 0.712 | Std Log Loss: 0.009\n",
      "7. Weights: [0.0, 0.07, 0.37, 0.57] | Mean Accuracy: 0.695 | Std Accuracy: 0.015 | Mean Log Loss: 0.719 | Std Log Loss: 0.009\n",
      "8. Weights: [0.0, 0.07, 0.4, 0.53] | Mean Accuracy: 0.695 | Std Accuracy: 0.014 | Mean Log Loss: 0.718 | Std Log Loss: 0.009\n",
      "9. Weights: [0.0, 0.13, 0.37, 0.5] | Mean Accuracy: 0.695 | Std Accuracy: 0.012 | Mean Log Loss: 0.718 | Std Log Loss: 0.009\n",
      "10. Weights: [0.07, 0.07, 0.37, 0.5] | Mean Accuracy: 0.695 | Std Accuracy: 0.014 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "11. Weights: [0.0, 0.13, 0.33, 0.53] | Mean Accuracy: 0.695 | Std Accuracy: 0.012 | Mean Log Loss: 0.719 | Std Log Loss: 0.009\n",
      "12. Weights: [0.03, 0.1, 0.37, 0.5] | Mean Accuracy: 0.695 | Std Accuracy: 0.013 | Mean Log Loss: 0.716 | Std Log Loss: 0.009\n",
      "13. Weights: [0.03, 0.1, 0.4, 0.47] | Mean Accuracy: 0.695 | Std Accuracy: 0.013 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "14. Weights: [0.03, 0.17, 0.37, 0.43] | Mean Accuracy: 0.695 | Std Accuracy: 0.012 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "15. Weights: [0.07, 0.1, 0.4, 0.43] | Mean Accuracy: 0.695 | Std Accuracy: 0.013 | Mean Log Loss: 0.713 | Std Log Loss: 0.009\n",
      "16. Weights: [0.07, 0.17, 0.37, 0.4] | Mean Accuracy: 0.695 | Std Accuracy: 0.011 | Mean Log Loss: 0.713 | Std Log Loss: 0.009\n",
      "17. Weights: [0.07, 0.2, 0.37, 0.37] | Mean Accuracy: 0.695 | Std Accuracy: 0.010 | Mean Log Loss: 0.713 | Std Log Loss: 0.009\n",
      "18. Weights: [0.1, 0.1, 0.4, 0.4] | Mean Accuracy: 0.695 | Std Accuracy: 0.013 | Mean Log Loss: 0.711 | Std Log Loss: 0.009\n",
      "19. Weights: [0.03, 0.1, 0.33, 0.53] | Mean Accuracy: 0.695 | Std Accuracy: 0.012 | Mean Log Loss: 0.718 | Std Log Loss: 0.009\n",
      "20. Weights: [0.03, 0.13, 0.4, 0.43] | Mean Accuracy: 0.695 | Std Accuracy: 0.011 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "21. Weights: [0.07, 0.13, 0.4, 0.4] | Mean Accuracy: 0.695 | Std Accuracy: 0.012 | Mean Log Loss: 0.712 | Std Log Loss: 0.009\n",
      "22. Weights: [0.07, 0.2, 0.33, 0.4] | Mean Accuracy: 0.695 | Std Accuracy: 0.011 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "23. Weights: [0.07, 0.1, 0.33, 0.5] | Mean Accuracy: 0.695 | Std Accuracy: 0.013 | Mean Log Loss: 0.716 | Std Log Loss: 0.009\n",
      "24. Weights: [0.0, 0.03, 0.37, 0.6] | Mean Accuracy: 0.695 | Std Accuracy: 0.015 | Mean Log Loss: 0.720 | Std Log Loss: 0.009\n",
      "25. Weights: [0.0, 0.1, 0.37, 0.53] | Mean Accuracy: 0.695 | Std Accuracy: 0.013 | Mean Log Loss: 0.718 | Std Log Loss: 0.009\n",
      "26. Weights: [0.0, 0.17, 0.37, 0.47] | Mean Accuracy: 0.695 | Std Accuracy: 0.011 | Mean Log Loss: 0.717 | Std Log Loss: 0.009\n",
      "27. Weights: [0.03, 0.07, 0.33, 0.57] | Mean Accuracy: 0.695 | Std Accuracy: 0.014 | Mean Log Loss: 0.718 | Std Log Loss: 0.009\n",
      "28. Weights: [0.1, 0.1, 0.33, 0.47] | Mean Accuracy: 0.695 | Std Accuracy: 0.013 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "29. Weights: [0.1, 0.2, 0.33, 0.37] | Mean Accuracy: 0.695 | Std Accuracy: 0.012 | Mean Log Loss: 0.712 | Std Log Loss: 0.009\n",
      "30. Weights: [0.0, 0.17, 0.33, 0.5] | Mean Accuracy: 0.695 | Std Accuracy: 0.012 | Mean Log Loss: 0.719 | Std Log Loss: 0.009\n",
      "31. Weights: [0.03, 0.13, 0.33, 0.5] | Mean Accuracy: 0.695 | Std Accuracy: 0.013 | Mean Log Loss: 0.717 | Std Log Loss: 0.009\n",
      "32. Weights: [0.07, 0.1, 0.37, 0.47] | Mean Accuracy: 0.695 | Std Accuracy: 0.012 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "33. Weights: [0.13, 0.17, 0.33, 0.37] | Mean Accuracy: 0.695 | Std Accuracy: 0.013 | Mean Log Loss: 0.711 | Std Log Loss: 0.009\n",
      "34. Weights: [0.0, 0.07, 0.33, 0.6] | Mean Accuracy: 0.695 | Std Accuracy: 0.015 | Mean Log Loss: 0.721 | Std Log Loss: 0.009\n",
      "35. Weights: [0.03, 0.07, 0.4, 0.5] | Mean Accuracy: 0.695 | Std Accuracy: 0.014 | Mean Log Loss: 0.716 | Std Log Loss: 0.009\n",
      "36. Weights: [0.07, 0.13, 0.3, 0.5] | Mean Accuracy: 0.695 | Std Accuracy: 0.013 | Mean Log Loss: 0.717 | Std Log Loss: 0.009\n",
      "37. Weights: [0.1, 0.1, 0.3, 0.5] | Mean Accuracy: 0.695 | Std Accuracy: 0.013 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "38. Weights: [0.1, 0.1, 0.37, 0.43] | Mean Accuracy: 0.695 | Std Accuracy: 0.013 | Mean Log Loss: 0.712 | Std Log Loss: 0.009\n",
      "39. Weights: [0.13, 0.13, 0.37, 0.37] | Mean Accuracy: 0.695 | Std Accuracy: 0.012 | Mean Log Loss: 0.710 | Std Log Loss: 0.009\n",
      "40. Weights: [0.13, 0.23, 0.23, 0.4] | Mean Accuracy: 0.695 | Std Accuracy: 0.010 | Mean Log Loss: 0.714 | Std Log Loss: 0.008\n",
      "41. Weights: [0.03, 0.03, 0.4, 0.53] | Mean Accuracy: 0.695 | Std Accuracy: 0.014 | Mean Log Loss: 0.716 | Std Log Loss: 0.009\n",
      "42. Weights: [0.07, 0.13, 0.33, 0.47] | Mean Accuracy: 0.695 | Std Accuracy: 0.012 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "43. Weights: [0.0, 0.0, 0.37, 0.63] | Mean Accuracy: 0.694 | Std Accuracy: 0.013 | Mean Log Loss: 0.721 | Std Log Loss: 0.009\n",
      "44. Weights: [0.0, 0.1, 0.4, 0.5] | Mean Accuracy: 0.694 | Std Accuracy: 0.012 | Mean Log Loss: 0.717 | Std Log Loss: 0.009\n",
      "45. Weights: [0.07, 0.07, 0.33, 0.53] | Mean Accuracy: 0.694 | Std Accuracy: 0.014 | Mean Log Loss: 0.716 | Std Log Loss: 0.009\n",
      "46. Weights: [0.07, 0.07, 0.4, 0.47] | Mean Accuracy: 0.694 | Std Accuracy: 0.014 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "47. Weights: [0.07, 0.2, 0.3, 0.43] | Mean Accuracy: 0.694 | Std Accuracy: 0.010 | Mean Log Loss: 0.716 | Std Log Loss: 0.009\n",
      "48. Weights: [0.13, 0.13, 0.33, 0.4] | Mean Accuracy: 0.694 | Std Accuracy: 0.013 | Mean Log Loss: 0.711 | Std Log Loss: 0.009\n",
      "49. Weights: [0.0, 0.03, 0.4, 0.57] | Mean Accuracy: 0.694 | Std Accuracy: 0.014 | Mean Log Loss: 0.718 | Std Log Loss: 0.009\n",
      "50. Weights: [0.07, 0.07, 0.2, 0.67] | Mean Accuracy: 0.694 | Std Accuracy: 0.013 | Mean Log Loss: 0.723 | Std Log Loss: 0.008\n",
      "51. Weights: [0.07, 0.07, 0.23, 0.63] | Mean Accuracy: 0.694 | Std Accuracy: 0.013 | Mean Log Loss: 0.721 | Std Log Loss: 0.008\n",
      "52. Weights: [0.07, 0.17, 0.33, 0.43] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "53. Weights: [0.1, 0.13, 0.33, 0.43] | Mean Accuracy: 0.694 | Std Accuracy: 0.013 | Mean Log Loss: 0.713 | Std Log Loss: 0.009\n",
      "54. Weights: [0.1, 0.17, 0.37, 0.37] | Mean Accuracy: 0.694 | Std Accuracy: 0.013 | Mean Log Loss: 0.711 | Std Log Loss: 0.009\n",
      "55. Weights: [0.0, 0.0, 0.43, 0.57] | Mean Accuracy: 0.694 | Std Accuracy: 0.014 | Mean Log Loss: 0.718 | Std Log Loss: 0.009\n",
      "56. Weights: [0.0, 0.17, 0.27, 0.57] | Mean Accuracy: 0.694 | Std Accuracy: 0.010 | Mean Log Loss: 0.722 | Std Log Loss: 0.008\n",
      "57. Weights: [0.03, 0.1, 0.43, 0.43] | Mean Accuracy: 0.694 | Std Accuracy: 0.013 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "58. Weights: [0.07, 0.17, 0.27, 0.5] | Mean Accuracy: 0.694 | Std Accuracy: 0.010 | Mean Log Loss: 0.718 | Std Log Loss: 0.008\n",
      "59. Weights: [0.1, 0.17, 0.33, 0.4] | Mean Accuracy: 0.694 | Std Accuracy: 0.013 | Mean Log Loss: 0.713 | Std Log Loss: 0.009\n",
      "60. Weights: [0.17, 0.23, 0.23, 0.37] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.713 | Std Log Loss: 0.009\n",
      "61. Weights: [0.07, 0.23, 0.3, 0.4] | Mean Accuracy: 0.694 | Std Accuracy: 0.009 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "62. Weights: [0.07, 0.23, 0.33, 0.37] | Mean Accuracy: 0.694 | Std Accuracy: 0.010 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "63. Weights: [0.13, 0.2, 0.3, 0.37] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.712 | Std Log Loss: 0.009\n",
      "64. Weights: [0.0, 0.0, 0.4, 0.6] | Mean Accuracy: 0.694 | Std Accuracy: 0.015 | Mean Log Loss: 0.719 | Std Log Loss: 0.009\n",
      "65. Weights: [0.03, 0.2, 0.37, 0.4] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "66. Weights: [0.0, 0.1, 0.43, 0.47] | Mean Accuracy: 0.694 | Std Accuracy: 0.012 | Mean Log Loss: 0.716 | Std Log Loss: 0.009\n",
      "67. Weights: [0.0, 0.17, 0.3, 0.53] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.720 | Std Log Loss: 0.009\n",
      "68. Weights: [0.03, 0.03, 0.27, 0.67] | Mean Accuracy: 0.694 | Std Accuracy: 0.015 | Mean Log Loss: 0.722 | Std Log Loss: 0.009\n",
      "69. Weights: [0.03, 0.03, 0.43, 0.5] | Mean Accuracy: 0.694 | Std Accuracy: 0.014 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "70. Weights: [0.03, 0.07, 0.27, 0.63] | Mean Accuracy: 0.694 | Std Accuracy: 0.014 | Mean Log Loss: 0.722 | Std Log Loss: 0.008\n",
      "71. Weights: [0.07, 0.2, 0.27, 0.47] | Mean Accuracy: 0.694 | Std Accuracy: 0.010 | Mean Log Loss: 0.717 | Std Log Loss: 0.008\n",
      "72. Weights: [0.1, 0.17, 0.3, 0.43] | Mean Accuracy: 0.694 | Std Accuracy: 0.012 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "73. Weights: [0.1, 0.2, 0.23, 0.47] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.717 | Std Log Loss: 0.008\n",
      "74. Weights: [0.13, 0.17, 0.3, 0.4] | Mean Accuracy: 0.694 | Std Accuracy: 0.012 | Mean Log Loss: 0.712 | Std Log Loss: 0.009\n",
      "75. Weights: [0.13, 0.2, 0.23, 0.43] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.715 | Std Log Loss: 0.008\n",
      "76. Weights: [0.17, 0.17, 0.33, 0.33] | Mean Accuracy: 0.694 | Std Accuracy: 0.012 | Mean Log Loss: 0.709 | Std Log Loss: 0.009\n",
      "77. Weights: [0.0, 0.03, 0.43, 0.53] | Mean Accuracy: 0.694 | Std Accuracy: 0.014 | Mean Log Loss: 0.717 | Std Log Loss: 0.009\n",
      "78. Weights: [0.0, 0.0, 0.47, 0.53] | Mean Accuracy: 0.694 | Std Accuracy: 0.013 | Mean Log Loss: 0.717 | Std Log Loss: 0.010\n",
      "79. Weights: [0.1, 0.23, 0.33, 0.33] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.712 | Std Log Loss: 0.009\n",
      "80. Weights: [0.17, 0.2, 0.23, 0.4] | Mean Accuracy: 0.694 | Std Accuracy: 0.012 | Mean Log Loss: 0.713 | Std Log Loss: 0.009\n",
      "81. Weights: [0.0, 0.07, 0.43, 0.5] | Mean Accuracy: 0.694 | Std Accuracy: 0.013 | Mean Log Loss: 0.716 | Std Log Loss: 0.009\n",
      "82. Weights: [0.03, 0.03, 0.33, 0.6] | Mean Accuracy: 0.694 | Std Accuracy: 0.013 | Mean Log Loss: 0.719 | Std Log Loss: 0.009\n",
      "83. Weights: [0.03, 0.07, 0.3, 0.6] | Mean Accuracy: 0.694 | Std Accuracy: 0.014 | Mean Log Loss: 0.720 | Std Log Loss: 0.009\n",
      "84. Weights: [0.03, 0.17, 0.33, 0.47] | Mean Accuracy: 0.694 | Std Accuracy: 0.012 | Mean Log Loss: 0.717 | Std Log Loss: 0.009\n",
      "85. Weights: [0.03, 0.2, 0.33, 0.43] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.716 | Std Log Loss: 0.009\n",
      "86. Weights: [0.03, 0.23, 0.33, 0.4] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.716 | Std Log Loss: 0.009\n",
      "87. Weights: [0.07, 0.07, 0.27, 0.6] | Mean Accuracy: 0.694 | Std Accuracy: 0.013 | Mean Log Loss: 0.719 | Std Log Loss: 0.009\n",
      "88. Weights: [0.07, 0.1, 0.3, 0.53] | Mean Accuracy: 0.694 | Std Accuracy: 0.013 | Mean Log Loss: 0.717 | Std Log Loss: 0.009\n",
      "89. Weights: [0.07, 0.13, 0.27, 0.53] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.718 | Std Log Loss: 0.008\n",
      "90. Weights: [0.07, 0.17, 0.3, 0.47] | Mean Accuracy: 0.694 | Std Accuracy: 0.012 | Mean Log Loss: 0.716 | Std Log Loss: 0.009\n",
      "91. Weights: [0.1, 0.13, 0.2, 0.57] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.719 | Std Log Loss: 0.008\n",
      "92. Weights: [0.1, 0.23, 0.23, 0.43] | Mean Accuracy: 0.694 | Std Accuracy: 0.010 | Mean Log Loss: 0.716 | Std Log Loss: 0.008\n",
      "93. Weights: [0.13, 0.2, 0.27, 0.4] | Mean Accuracy: 0.694 | Std Accuracy: 0.010 | Mean Log Loss: 0.713 | Std Log Loss: 0.009\n",
      "94. Weights: [0.17, 0.2, 0.27, 0.37] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.711 | Std Log Loss: 0.009\n",
      "95. Weights: [0.0, 0.0, 0.2, 0.8] | Mean Accuracy: 0.694 | Std Accuracy: 0.015 | Mean Log Loss: 0.729 | Std Log Loss: 0.008\n",
      "96. Weights: [0.0, 0.03, 0.47, 0.5] | Mean Accuracy: 0.694 | Std Accuracy: 0.014 | Mean Log Loss: 0.716 | Std Log Loss: 0.010\n",
      "97. Weights: [0.0, 0.07, 0.23, 0.7] | Mean Accuracy: 0.694 | Std Accuracy: 0.014 | Mean Log Loss: 0.726 | Std Log Loss: 0.008\n",
      "98. Weights: [0.1, 0.2, 0.3, 0.4] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "99. Weights: [0.13, 0.2, 0.33, 0.33] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.710 | Std Log Loss: 0.009\n",
      "100. Weights: [0.0, 0.0, 0.23, 0.77] | Mean Accuracy: 0.694 | Std Accuracy: 0.016 | Mean Log Loss: 0.728 | Std Log Loss: 0.008\n",
      "\n",
      "Bottom 100 Log Losses:\n",
      "1. Weights: [0.23, 0.23, 0.27, 0.27] | Mean Accuracy: 0.693 | Std Accuracy: 0.008 | Mean Log Loss: 0.708 | Std Log Loss: 0.009\n",
      "2. Weights: [0.2, 0.2, 0.3, 0.3] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.708 | Std Log Loss: 0.009\n",
      "3. Weights: [0.17, 0.17, 0.33, 0.33] | Mean Accuracy: 0.694 | Std Accuracy: 0.012 | Mean Log Loss: 0.709 | Std Log Loss: 0.009\n",
      "4. Weights: [0.23, 0.23, 0.23, 0.3] | Mean Accuracy: 0.693 | Std Accuracy: 0.009 | Mean Log Loss: 0.709 | Std Log Loss: 0.009\n",
      "5. Weights: [0.2, 0.27, 0.27, 0.27] | Mean Accuracy: 0.693 | Std Accuracy: 0.008 | Mean Log Loss: 0.709 | Std Log Loss: 0.009\n",
      "6. Weights: [0.2, 0.23, 0.27, 0.3] | Mean Accuracy: 0.693 | Std Accuracy: 0.010 | Mean Log Loss: 0.709 | Std Log Loss: 0.009\n",
      "7. Weights: [0.2, 0.2, 0.27, 0.33] | Mean Accuracy: 0.693 | Std Accuracy: 0.011 | Mean Log Loss: 0.710 | Std Log Loss: 0.009\n",
      "8. Weights: [0.17, 0.23, 0.3, 0.3] | Mean Accuracy: 0.692 | Std Accuracy: 0.009 | Mean Log Loss: 0.710 | Std Log Loss: 0.009\n",
      "9. Weights: [0.13, 0.13, 0.37, 0.37] | Mean Accuracy: 0.695 | Std Accuracy: 0.012 | Mean Log Loss: 0.710 | Std Log Loss: 0.009\n",
      "10. Weights: [0.17, 0.2, 0.3, 0.33] | Mean Accuracy: 0.693 | Std Accuracy: 0.011 | Mean Log Loss: 0.710 | Std Log Loss: 0.009\n",
      "11. Weights: [0.17, 0.17, 0.3, 0.37] | Mean Accuracy: 0.694 | Std Accuracy: 0.012 | Mean Log Loss: 0.710 | Std Log Loss: 0.009\n",
      "12. Weights: [0.13, 0.2, 0.33, 0.33] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.710 | Std Log Loss: 0.009\n",
      "13. Weights: [0.2, 0.23, 0.23, 0.33] | Mean Accuracy: 0.693 | Std Accuracy: 0.011 | Mean Log Loss: 0.711 | Std Log Loss: 0.009\n",
      "14. Weights: [0.13, 0.17, 0.33, 0.37] | Mean Accuracy: 0.695 | Std Accuracy: 0.013 | Mean Log Loss: 0.711 | Std Log Loss: 0.009\n",
      "15. Weights: [0.2, 0.2, 0.23, 0.37] | Mean Accuracy: 0.693 | Std Accuracy: 0.011 | Mean Log Loss: 0.711 | Std Log Loss: 0.009\n",
      "16. Weights: [0.17, 0.27, 0.27, 0.3] | Mean Accuracy: 0.693 | Std Accuracy: 0.009 | Mean Log Loss: 0.711 | Std Log Loss: 0.009\n",
      "17. Weights: [0.1, 0.1, 0.4, 0.4] | Mean Accuracy: 0.695 | Std Accuracy: 0.013 | Mean Log Loss: 0.711 | Std Log Loss: 0.009\n",
      "18. Weights: [0.17, 0.23, 0.27, 0.33] | Mean Accuracy: 0.693 | Std Accuracy: 0.010 | Mean Log Loss: 0.711 | Std Log Loss: 0.009\n",
      "19. Weights: [0.13, 0.13, 0.33, 0.4] | Mean Accuracy: 0.694 | Std Accuracy: 0.013 | Mean Log Loss: 0.711 | Std Log Loss: 0.009\n",
      "20. Weights: [0.17, 0.2, 0.27, 0.37] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.711 | Std Log Loss: 0.009\n",
      "21. Weights: [0.1, 0.17, 0.37, 0.37] | Mean Accuracy: 0.694 | Std Accuracy: 0.013 | Mean Log Loss: 0.711 | Std Log Loss: 0.009\n",
      "22. Weights: [0.13, 0.27, 0.3, 0.3] | Mean Accuracy: 0.693 | Std Accuracy: 0.009 | Mean Log Loss: 0.711 | Std Log Loss: 0.009\n",
      "23. Weights: [0.13, 0.23, 0.3, 0.33] | Mean Accuracy: 0.692 | Std Accuracy: 0.009 | Mean Log Loss: 0.712 | Std Log Loss: 0.009\n",
      "24. Weights: [0.17, 0.17, 0.27, 0.4] | Mean Accuracy: 0.693 | Std Accuracy: 0.013 | Mean Log Loss: 0.712 | Std Log Loss: 0.009\n",
      "25. Weights: [0.1, 0.13, 0.37, 0.4] | Mean Accuracy: 0.696 | Std Accuracy: 0.012 | Mean Log Loss: 0.712 | Std Log Loss: 0.009\n",
      "26. Weights: [0.13, 0.2, 0.3, 0.37] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.712 | Std Log Loss: 0.009\n",
      "27. Weights: [0.13, 0.17, 0.3, 0.4] | Mean Accuracy: 0.694 | Std Accuracy: 0.012 | Mean Log Loss: 0.712 | Std Log Loss: 0.009\n",
      "28. Weights: [0.1, 0.23, 0.33, 0.33] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.712 | Std Log Loss: 0.009\n",
      "29. Weights: [0.1, 0.1, 0.37, 0.43] | Mean Accuracy: 0.695 | Std Accuracy: 0.013 | Mean Log Loss: 0.712 | Std Log Loss: 0.009\n",
      "30. Weights: [0.07, 0.07, 0.43, 0.43] | Mean Accuracy: 0.693 | Std Accuracy: 0.014 | Mean Log Loss: 0.712 | Std Log Loss: 0.009\n",
      "31. Weights: [0.1, 0.2, 0.33, 0.37] | Mean Accuracy: 0.695 | Std Accuracy: 0.012 | Mean Log Loss: 0.712 | Std Log Loss: 0.009\n",
      "32. Weights: [0.2, 0.2, 0.2, 0.4] | Mean Accuracy: 0.692 | Std Accuracy: 0.011 | Mean Log Loss: 0.712 | Std Log Loss: 0.008\n",
      "33. Weights: [0.07, 0.13, 0.4, 0.4] | Mean Accuracy: 0.695 | Std Accuracy: 0.012 | Mean Log Loss: 0.712 | Std Log Loss: 0.009\n",
      "34. Weights: [0.17, 0.23, 0.23, 0.37] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.713 | Std Log Loss: 0.009\n",
      "35. Weights: [0.13, 0.13, 0.3, 0.43] | Mean Accuracy: 0.693 | Std Accuracy: 0.013 | Mean Log Loss: 0.713 | Std Log Loss: 0.009\n",
      "36. Weights: [0.1, 0.17, 0.33, 0.4] | Mean Accuracy: 0.694 | Std Accuracy: 0.013 | Mean Log Loss: 0.713 | Std Log Loss: 0.009\n",
      "37. Weights: [0.17, 0.2, 0.23, 0.4] | Mean Accuracy: 0.694 | Std Accuracy: 0.012 | Mean Log Loss: 0.713 | Std Log Loss: 0.009\n",
      "38. Weights: [0.13, 0.27, 0.27, 0.33] | Mean Accuracy: 0.692 | Std Accuracy: 0.009 | Mean Log Loss: 0.713 | Std Log Loss: 0.009\n",
      "39. Weights: [0.07, 0.1, 0.4, 0.43] | Mean Accuracy: 0.695 | Std Accuracy: 0.013 | Mean Log Loss: 0.713 | Std Log Loss: 0.009\n",
      "40. Weights: [0.13, 0.23, 0.27, 0.37] | Mean Accuracy: 0.693 | Std Accuracy: 0.009 | Mean Log Loss: 0.713 | Std Log Loss: 0.009\n",
      "41. Weights: [0.07, 0.2, 0.37, 0.37] | Mean Accuracy: 0.695 | Std Accuracy: 0.010 | Mean Log Loss: 0.713 | Std Log Loss: 0.009\n",
      "42. Weights: [0.1, 0.13, 0.33, 0.43] | Mean Accuracy: 0.694 | Std Accuracy: 0.013 | Mean Log Loss: 0.713 | Std Log Loss: 0.009\n",
      "43. Weights: [0.17, 0.17, 0.23, 0.43] | Mean Accuracy: 0.693 | Std Accuracy: 0.012 | Mean Log Loss: 0.713 | Std Log Loss: 0.008\n",
      "44. Weights: [0.13, 0.2, 0.27, 0.4] | Mean Accuracy: 0.694 | Std Accuracy: 0.010 | Mean Log Loss: 0.713 | Std Log Loss: 0.009\n",
      "45. Weights: [0.1, 0.3, 0.3, 0.3] | Mean Accuracy: 0.692 | Std Accuracy: 0.007 | Mean Log Loss: 0.713 | Std Log Loss: 0.009\n",
      "46. Weights: [0.07, 0.17, 0.37, 0.4] | Mean Accuracy: 0.695 | Std Accuracy: 0.011 | Mean Log Loss: 0.713 | Std Log Loss: 0.009\n",
      "47. Weights: [0.1, 0.27, 0.3, 0.33] | Mean Accuracy: 0.692 | Std Accuracy: 0.009 | Mean Log Loss: 0.713 | Std Log Loss: 0.009\n",
      "48. Weights: [0.1, 0.23, 0.3, 0.37] | Mean Accuracy: 0.693 | Std Accuracy: 0.009 | Mean Log Loss: 0.713 | Std Log Loss: 0.009\n",
      "49. Weights: [0.07, 0.07, 0.4, 0.47] | Mean Accuracy: 0.694 | Std Accuracy: 0.014 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "50. Weights: [0.13, 0.17, 0.27, 0.43] | Mean Accuracy: 0.693 | Std Accuracy: 0.011 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "51. Weights: [0.1, 0.1, 0.33, 0.47] | Mean Accuracy: 0.695 | Std Accuracy: 0.013 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "52. Weights: [0.03, 0.1, 0.43, 0.43] | Mean Accuracy: 0.694 | Std Accuracy: 0.013 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "53. Weights: [0.1, 0.2, 0.3, 0.4] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "54. Weights: [0.07, 0.13, 0.37, 0.43] | Mean Accuracy: 0.696 | Std Accuracy: 0.012 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "55. Weights: [0.03, 0.03, 0.47, 0.47] | Mean Accuracy: 0.693 | Std Accuracy: 0.012 | Mean Log Loss: 0.714 | Std Log Loss: 0.010\n",
      "56. Weights: [0.07, 0.27, 0.33, 0.33] | Mean Accuracy: 0.693 | Std Accuracy: 0.009 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "57. Weights: [0.13, 0.13, 0.27, 0.47] | Mean Accuracy: 0.693 | Std Accuracy: 0.012 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "58. Weights: [0.03, 0.17, 0.4, 0.4] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "59. Weights: [0.07, 0.23, 0.33, 0.37] | Mean Accuracy: 0.694 | Std Accuracy: 0.010 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "60. Weights: [0.1, 0.17, 0.3, 0.43] | Mean Accuracy: 0.694 | Std Accuracy: 0.012 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "61. Weights: [0.07, 0.1, 0.37, 0.47] | Mean Accuracy: 0.695 | Std Accuracy: 0.012 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "62. Weights: [0.07, 0.2, 0.33, 0.4] | Mean Accuracy: 0.695 | Std Accuracy: 0.011 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "63. Weights: [0.03, 0.07, 0.43, 0.47] | Mean Accuracy: 0.693 | Std Accuracy: 0.014 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "64. Weights: [0.17, 0.2, 0.2, 0.43] | Mean Accuracy: 0.693 | Std Accuracy: 0.011 | Mean Log Loss: 0.714 | Std Log Loss: 0.008\n",
      "65. Weights: [0.13, 0.23, 0.23, 0.4] | Mean Accuracy: 0.695 | Std Accuracy: 0.010 | Mean Log Loss: 0.714 | Std Log Loss: 0.008\n",
      "66. Weights: [0.03, 0.13, 0.4, 0.43] | Mean Accuracy: 0.695 | Std Accuracy: 0.011 | Mean Log Loss: 0.714 | Std Log Loss: 0.009\n",
      "67. Weights: [0.1, 0.13, 0.3, 0.47] | Mean Accuracy: 0.693 | Std Accuracy: 0.013 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "68. Weights: [0.07, 0.17, 0.33, 0.43] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "69. Weights: [0.1, 0.27, 0.27, 0.37] | Mean Accuracy: 0.692 | Std Accuracy: 0.009 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "70. Weights: [0.13, 0.2, 0.23, 0.43] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.715 | Std Log Loss: 0.008\n",
      "71. Weights: [0.17, 0.17, 0.2, 0.47] | Mean Accuracy: 0.693 | Std Accuracy: 0.011 | Mean Log Loss: 0.715 | Std Log Loss: 0.008\n",
      "72. Weights: [0.03, 0.23, 0.37, 0.37] | Mean Accuracy: 0.693 | Std Accuracy: 0.010 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "73. Weights: [0.1, 0.23, 0.27, 0.4] | Mean Accuracy: 0.693 | Std Accuracy: 0.010 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "74. Weights: [0.07, 0.07, 0.37, 0.5] | Mean Accuracy: 0.695 | Std Accuracy: 0.014 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "75. Weights: [0.03, 0.2, 0.37, 0.4] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "76. Weights: [0.03, 0.1, 0.4, 0.47] | Mean Accuracy: 0.695 | Std Accuracy: 0.013 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "77. Weights: [0.03, 0.03, 0.43, 0.5] | Mean Accuracy: 0.694 | Std Accuracy: 0.014 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "78. Weights: [0.1, 0.1, 0.3, 0.5] | Mean Accuracy: 0.695 | Std Accuracy: 0.013 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "79. Weights: [0.13, 0.17, 0.23, 0.47] | Mean Accuracy: 0.692 | Std Accuracy: 0.010 | Mean Log Loss: 0.715 | Std Log Loss: 0.008\n",
      "80. Weights: [0.07, 0.13, 0.33, 0.47] | Mean Accuracy: 0.695 | Std Accuracy: 0.012 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "81. Weights: [0.0, 0.07, 0.47, 0.47] | Mean Accuracy: 0.693 | Std Accuracy: 0.012 | Mean Log Loss: 0.715 | Std Log Loss: 0.010\n",
      "82. Weights: [0.1, 0.2, 0.27, 0.43] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "83. Weights: [0.07, 0.3, 0.3, 0.33] | Mean Accuracy: 0.692 | Std Accuracy: 0.007 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "84. Weights: [0.07, 0.27, 0.3, 0.37] | Mean Accuracy: 0.693 | Std Accuracy: 0.009 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "85. Weights: [0.0, 0.13, 0.43, 0.43] | Mean Accuracy: 0.693 | Std Accuracy: 0.012 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "86. Weights: [0.03, 0.17, 0.37, 0.43] | Mean Accuracy: 0.695 | Std Accuracy: 0.012 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "87. Weights: [0.07, 0.23, 0.3, 0.4] | Mean Accuracy: 0.694 | Std Accuracy: 0.009 | Mean Log Loss: 0.715 | Std Log Loss: 0.009\n",
      "88. Weights: [0.0, 0.0, 0.5, 0.5] | Mean Accuracy: 0.693 | Std Accuracy: 0.012 | Mean Log Loss: 0.715 | Std Log Loss: 0.010\n",
      "89. Weights: [0.1, 0.17, 0.27, 0.47] | Mean Accuracy: 0.693 | Std Accuracy: 0.010 | Mean Log Loss: 0.716 | Std Log Loss: 0.009\n",
      "90. Weights: [0.13, 0.13, 0.23, 0.5] | Mean Accuracy: 0.693 | Std Accuracy: 0.012 | Mean Log Loss: 0.716 | Std Log Loss: 0.008\n",
      "91. Weights: [0.03, 0.07, 0.4, 0.5] | Mean Accuracy: 0.695 | Std Accuracy: 0.014 | Mean Log Loss: 0.716 | Std Log Loss: 0.009\n",
      "92. Weights: [0.07, 0.1, 0.33, 0.5] | Mean Accuracy: 0.695 | Std Accuracy: 0.013 | Mean Log Loss: 0.716 | Std Log Loss: 0.009\n",
      "93. Weights: [0.07, 0.2, 0.3, 0.43] | Mean Accuracy: 0.694 | Std Accuracy: 0.010 | Mean Log Loss: 0.716 | Std Log Loss: 0.009\n",
      "94. Weights: [0.0, 0.2, 0.4, 0.4] | Mean Accuracy: 0.692 | Std Accuracy: 0.010 | Mean Log Loss: 0.716 | Std Log Loss: 0.009\n",
      "95. Weights: [0.0, 0.1, 0.43, 0.47] | Mean Accuracy: 0.694 | Std Accuracy: 0.012 | Mean Log Loss: 0.716 | Std Log Loss: 0.009\n",
      "96. Weights: [0.03, 0.13, 0.37, 0.47] | Mean Accuracy: 0.696 | Std Accuracy: 0.012 | Mean Log Loss: 0.716 | Std Log Loss: 0.009\n",
      "97. Weights: [0.03, 0.3, 0.33, 0.33] | Mean Accuracy: 0.691 | Std Accuracy: 0.008 | Mean Log Loss: 0.716 | Std Log Loss: 0.009\n",
      "98. Weights: [0.0, 0.03, 0.47, 0.5] | Mean Accuracy: 0.694 | Std Accuracy: 0.014 | Mean Log Loss: 0.716 | Std Log Loss: 0.010\n",
      "99. Weights: [0.03, 0.27, 0.33, 0.37] | Mean Accuracy: 0.693 | Std Accuracy: 0.008 | Mean Log Loss: 0.716 | Std Log Loss: 0.009\n",
      "100. Weights: [0.03, 0.23, 0.33, 0.4] | Mean Accuracy: 0.694 | Std Accuracy: 0.011 | Mean Log Loss: 0.716 | Std Log Loss: 0.009\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('params_xgb.json', 'r') as file:\n",
    "    xgb_params = json.load(file)\n",
    "\n",
    "with open('params_rf.json', 'r') as file: \n",
    "    rf_params = json.load(file)\n",
    "\n",
    "results, best_result = train_ensemble(\n",
    "    X_train, y_train, \n",
    "    xgb_params=xgb_params, rf_params=rf_params,\n",
    "    mean_type='arithmetic'\n",
    ")\n",
    "\n",
    "show_top_weights(results, n_top=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weights': (np.float64(0.23),\n",
       "  np.float64(0.23),\n",
       "  np.float64(0.27),\n",
       "  np.float64(0.27)),\n",
       " 'mean_accuracy': np.float64(0.6925999999999999),\n",
       " 'std_accuracy': np.float64(0.008309031231136361),\n",
       " 'mean_log_loss': np.float64(0.7075902518505988),\n",
       " 'std_log_loss': np.float64(0.008891453327921791)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def create_splits(X, y, train_size=0.8, bias_class=None, bias_ratio=0.6):\n",
    "    \"\"\"\n",
    "    Creates train-validation splits with different class distributions.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: Feature DataFrame\n",
    "    - y: Target labels (0, 1, 2) as a NumPy array\n",
    "    - train_size: Proportion of data to be used for training\n",
    "    - bias_class: Class to over-represent in training (None for balanced split)\n",
    "    - bias_ratio: Ratio of bias_class in train set (if bias_class is set)\n",
    "    \n",
    "    Returns:\n",
    "    - X_train, X_val, y_train, y_val: Train and validation splits\n",
    "    \"\"\"\n",
    "    if bias_class is None:\n",
    "        # Standard stratified split\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=train_size, stratify=y, random_state=42)\n",
    "    else:\n",
    "        # Split each class separately\n",
    "        indices = np.arange(len(y))\n",
    "        class_indices = {label: indices[y == label] for label in np.unique(y)}\n",
    "        \n",
    "        train_indices, val_indices = [], []\n",
    "        for label, idx in class_indices.items():\n",
    "            if label == bias_class:\n",
    "                train_count = int(len(idx) * bias_ratio)\n",
    "            else:\n",
    "                train_count = int(len(idx) * (1 - bias_ratio) / 2)\n",
    "            \n",
    "            train_idx, val_idx = train_test_split(idx, train_size=train_count, random_state=42)\n",
    "            train_indices.extend(train_idx)\n",
    "            val_indices.extend(val_idx)\n",
    "        \n",
    "        X_train, X_val = X.iloc[train_indices], X.iloc[val_indices]\n",
    "        y_train, y_val = y[train_indices], y[val_indices]\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1\n",
      "     Train distribution: Counter({np.int64(2): 1631, np.int64(0): 1262, np.int64(1): 1107})\n",
      "     Validation distribution: Counter({np.int64(2): 408, np.int64(0): 315, np.int64(1): 277})\n",
      "\n",
      "Split 2\n",
      "     Train distribution: Counter({np.int64(0): 946, np.int64(2): 407, np.int64(1): 276})\n",
      "     Validation distribution: Counter({np.int64(2): 1632, np.int64(1): 1108, np.int64(0): 631})\n",
      "\n",
      "Split 3\n",
      "     Train distribution: Counter({np.int64(1): 830, np.int64(2): 407, np.int64(0): 315})\n",
      "     Validation distribution: Counter({np.int64(2): 1632, np.int64(0): 1262, np.int64(1): 554})\n",
      "\n",
      "Split 4\n",
      "     Train distribution: Counter({np.int64(2): 1223, np.int64(0): 315, np.int64(1): 276})\n",
      "     Validation distribution: Counter({np.int64(0): 1262, np.int64(1): 1108, np.int64(2): 816})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from data import X_train as X \n",
    "from data import y_train as y\n",
    "\n",
    "# 1. Balanced split\n",
    "X_train1, X_val1, y_train1, y_val1 = create_splits(X, y)\n",
    "\n",
    "# 2. More class 0 in train\n",
    "X_train2, X_val2, y_train2, y_val2 = create_splits(X, y, bias_class=0, bias_ratio=0.6)\n",
    "\n",
    "# 3. More class 1 in train\n",
    "X_train3, X_val3, y_train3, y_val3 = create_splits(X, y, bias_class=1, bias_ratio=0.6)\n",
    "\n",
    "# 4. More class 2 in train\n",
    "X_train4, X_val4, y_train4, y_val4 = create_splits(X, y, bias_class=2, bias_ratio=0.6)\n",
    "\n",
    "# Print class distributions\n",
    "for i, (y_tr, y_v) in enumerate([(y_train1, y_val1), (y_train2, y_val2), (y_train3, y_val3), (y_train4, y_val4)], 1):\n",
    "    print(f\"Split {i}\\n     Train distribution: {Counter(y_tr)}\\n     Validation distribution: {Counter(y_v)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base_models import Model\n",
    "from ensemble import soft_voting, train_ensemble\n",
    "from model_nn import scale_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    1: (X_train1, X_val1, y_train1, y_val1),\n",
    "    2: (X_train2, X_val2, y_train2, y_val2),\n",
    "    3: (X_train3, X_val3, y_train3, y_val3),\n",
    "    4: (X_train4, X_val4, y_train4, y_val4)\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('params_xgb.json', 'r') as file:\n",
    "    xgb_params = json.load(file)\n",
    "\n",
    "with open('params_rf.json', 'r') as file: \n",
    "    rf_params = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING ITERATION 1\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Model trainings successful, proceeding to weight combination search...\n",
      "Weight combination search done.\n",
      "Top 5 Accuracies:\n",
      "1. Weights: [0.0, 0.2, 0.37, 0.43] | Mean Accuracy: 0.692 | Std Accuracy: 0.002 | Mean Log Loss: 0.721 | Std Log Loss: 0.011\n",
      "2. Weights: [0.0, 0.17, 0.33, 0.5] | Mean Accuracy: 0.692 | Std Accuracy: 0.002 | Mean Log Loss: 0.723 | Std Log Loss: 0.011\n",
      "3. Weights: [0.0, 0.2, 0.33, 0.47] | Mean Accuracy: 0.692 | Std Accuracy: 0.004 | Mean Log Loss: 0.723 | Std Log Loss: 0.011\n",
      "4. Weights: [0.0, 0.2, 0.4, 0.4] | Mean Accuracy: 0.692 | Std Accuracy: 0.003 | Mean Log Loss: 0.720 | Std Log Loss: 0.011\n",
      "5. Weights: [0.03, 0.17, 0.37, 0.43] | Mean Accuracy: 0.692 | Std Accuracy: 0.003 | Mean Log Loss: 0.720 | Std Log Loss: 0.011\n",
      "\n",
      "Bottom 5 Log Losses:\n",
      "1. Weights: [0.23, 0.23, 0.27, 0.27] | Mean Accuracy: 0.690 | Std Accuracy: 0.004 | Mean Log Loss: 0.711 | Std Log Loss: 0.012\n",
      "2. Weights: [0.2, 0.2, 0.3, 0.3] | Mean Accuracy: 0.691 | Std Accuracy: 0.004 | Mean Log Loss: 0.712 | Std Log Loss: 0.012\n",
      "3. Weights: [0.23, 0.23, 0.23, 0.3] | Mean Accuracy: 0.692 | Std Accuracy: 0.003 | Mean Log Loss: 0.712 | Std Log Loss: 0.012\n",
      "4. Weights: [0.2, 0.27, 0.27, 0.27] | Mean Accuracy: 0.689 | Std Accuracy: 0.004 | Mean Log Loss: 0.713 | Std Log Loss: 0.012\n",
      "5. Weights: [0.17, 0.17, 0.33, 0.33] | Mean Accuracy: 0.690 | Std Accuracy: 0.005 | Mean Log Loss: 0.713 | Std Log Loss: 0.012\n",
      "None \n",
      "\n",
      "RUNNING ITERATION 2\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Model trainings successful, proceeding to weight combination search...\n",
      "Weight combination search done.\n",
      "Top 5 Accuracies:\n",
      "1. Weights: [0.2, 0.23, 0.27, 0.3] | Mean Accuracy: 0.754 | Std Accuracy: 0.011 | Mean Log Loss: 0.618 | Std Log Loss: 0.010\n",
      "2. Weights: [0.13, 0.2, 0.27, 0.4] | Mean Accuracy: 0.754 | Std Accuracy: 0.008 | Mean Log Loss: 0.623 | Std Log Loss: 0.010\n",
      "3. Weights: [0.17, 0.23, 0.23, 0.37] | Mean Accuracy: 0.754 | Std Accuracy: 0.010 | Mean Log Loss: 0.621 | Std Log Loss: 0.010\n",
      "4. Weights: [0.17, 0.23, 0.27, 0.33] | Mean Accuracy: 0.754 | Std Accuracy: 0.010 | Mean Log Loss: 0.620 | Std Log Loss: 0.010\n",
      "5. Weights: [0.23, 0.23, 0.27, 0.27] | Mean Accuracy: 0.754 | Std Accuracy: 0.012 | Mean Log Loss: 0.617 | Std Log Loss: 0.011\n",
      "\n",
      "Bottom 5 Log Losses:\n",
      "1. Weights: [0.23, 0.23, 0.27, 0.27] | Mean Accuracy: 0.754 | Std Accuracy: 0.012 | Mean Log Loss: 0.617 | Std Log Loss: 0.011\n",
      "2. Weights: [0.2, 0.27, 0.27, 0.27] | Mean Accuracy: 0.751 | Std Accuracy: 0.013 | Mean Log Loss: 0.617 | Std Log Loss: 0.010\n",
      "3. Weights: [0.23, 0.23, 0.23, 0.3] | Mean Accuracy: 0.752 | Std Accuracy: 0.013 | Mean Log Loss: 0.618 | Std Log Loss: 0.010\n",
      "4. Weights: [0.2, 0.23, 0.27, 0.3] | Mean Accuracy: 0.754 | Std Accuracy: 0.011 | Mean Log Loss: 0.618 | Std Log Loss: 0.010\n",
      "5. Weights: [0.2, 0.2, 0.3, 0.3] | Mean Accuracy: 0.752 | Std Accuracy: 0.010 | Mean Log Loss: 0.618 | Std Log Loss: 0.010\n",
      "None \n",
      "\n",
      "RUNNING ITERATION 3\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Model trainings successful, proceeding to weight combination search...\n",
      "Weight combination search done.\n",
      "Top 5 Accuracies:\n",
      "1. Weights: [0.13, 0.2, 0.33, 0.33] | Mean Accuracy: 0.684 | Std Accuracy: 0.019 | Mean Log Loss: 0.721 | Std Log Loss: 0.019\n",
      "2. Weights: [0.23, 0.23, 0.27, 0.27] | Mean Accuracy: 0.683 | Std Accuracy: 0.024 | Mean Log Loss: 0.716 | Std Log Loss: 0.020\n",
      "3. Weights: [0.1, 0.17, 0.33, 0.4] | Mean Accuracy: 0.683 | Std Accuracy: 0.017 | Mean Log Loss: 0.725 | Std Log Loss: 0.018\n",
      "4. Weights: [0.1, 0.13, 0.37, 0.4] | Mean Accuracy: 0.682 | Std Accuracy: 0.015 | Mean Log Loss: 0.725 | Std Log Loss: 0.018\n",
      "5. Weights: [0.17, 0.2, 0.3, 0.33] | Mean Accuracy: 0.682 | Std Accuracy: 0.025 | Mean Log Loss: 0.720 | Std Log Loss: 0.019\n",
      "\n",
      "Bottom 5 Log Losses:\n",
      "1. Weights: [0.23, 0.23, 0.27, 0.27] | Mean Accuracy: 0.683 | Std Accuracy: 0.024 | Mean Log Loss: 0.716 | Std Log Loss: 0.020\n",
      "2. Weights: [0.23, 0.23, 0.23, 0.3] | Mean Accuracy: 0.680 | Std Accuracy: 0.025 | Mean Log Loss: 0.717 | Std Log Loss: 0.020\n",
      "3. Weights: [0.2, 0.27, 0.27, 0.27] | Mean Accuracy: 0.681 | Std Accuracy: 0.021 | Mean Log Loss: 0.718 | Std Log Loss: 0.020\n",
      "4. Weights: [0.2, 0.2, 0.3, 0.3] | Mean Accuracy: 0.682 | Std Accuracy: 0.024 | Mean Log Loss: 0.718 | Std Log Loss: 0.019\n",
      "5. Weights: [0.2, 0.23, 0.27, 0.3] | Mean Accuracy: 0.682 | Std Accuracy: 0.024 | Mean Log Loss: 0.718 | Std Log Loss: 0.020\n",
      "None \n",
      "\n",
      "RUNNING ITERATION 4\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Model trainings successful, proceeding to weight combination search...\n",
      "Weight combination search done.\n",
      "Top 5 Accuracies:\n",
      "1. Weights: [0.17, 0.17, 0.33, 0.33] | Mean Accuracy: 0.773 | Std Accuracy: 0.019 | Mean Log Loss: 0.587 | Std Log Loss: 0.027\n",
      "2. Weights: [0.07, 0.17, 0.3, 0.47] | Mean Accuracy: 0.772 | Std Accuracy: 0.018 | Mean Log Loss: 0.594 | Std Log Loss: 0.026\n",
      "3. Weights: [0.13, 0.13, 0.37, 0.37] | Mean Accuracy: 0.772 | Std Accuracy: 0.019 | Mean Log Loss: 0.590 | Std Log Loss: 0.026\n",
      "4. Weights: [0.17, 0.17, 0.23, 0.43] | Mean Accuracy: 0.772 | Std Accuracy: 0.020 | Mean Log Loss: 0.590 | Std Log Loss: 0.026\n",
      "5. Weights: [0.13, 0.17, 0.27, 0.43] | Mean Accuracy: 0.772 | Std Accuracy: 0.020 | Mean Log Loss: 0.591 | Std Log Loss: 0.026\n",
      "\n",
      "Bottom 5 Log Losses:\n",
      "1. Weights: [0.23, 0.23, 0.27, 0.27] | Mean Accuracy: 0.770 | Std Accuracy: 0.020 | Mean Log Loss: 0.584 | Std Log Loss: 0.027\n",
      "2. Weights: [0.23, 0.23, 0.23, 0.3] | Mean Accuracy: 0.770 | Std Accuracy: 0.020 | Mean Log Loss: 0.585 | Std Log Loss: 0.027\n",
      "3. Weights: [0.2, 0.27, 0.27, 0.27] | Mean Accuracy: 0.770 | Std Accuracy: 0.018 | Mean Log Loss: 0.585 | Std Log Loss: 0.027\n",
      "4. Weights: [0.2, 0.23, 0.27, 0.3] | Mean Accuracy: 0.771 | Std Accuracy: 0.020 | Mean Log Loss: 0.585 | Std Log Loss: 0.027\n",
      "5. Weights: [0.2, 0.2, 0.3, 0.3] | Mean Accuracy: 0.771 | Std Accuracy: 0.021 | Mean Log Loss: 0.586 | Std Log Loss: 0.027\n",
      "None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "simulation_results = {}\n",
    "\n",
    "for data_key in data:\n",
    "    print(f\"RUNNING ITERATION {data_key}\") \n",
    "    _X_train, _X_val, _y_train, _y_val = data[data_key]\n",
    "    results, best_result = train_ensemble(\n",
    "        _X_train, _y_train, xgb_params=xgb_params, rf_params=rf_params, mean_type='arithmetic'\n",
    "    )\n",
    "    print(show_top_weights(results), \"\\n\")\n",
    "\n",
    "    simulation_results[data_key] = (results, best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple \n",
    "\n",
    "class Ensemble: \n",
    "    def __init__(self, models: List[Model] = None, model_weights: np.ndarray = None):\n",
    "        if models is None: \n",
    "            self.xgb_model = Model(model_type='xgb', xgb_params=xgb_params)\n",
    "            self.gnb_model = Model(model_type='gnb', selected_features=['x2', 'x3', 'x4', 'x6', 'x8', 'x9', 'x10', 'x11'])\n",
    "            self.nn_model = Model(model_type='nn', nn_params=X.shape[1]) # TODO: replace with correct parameter later\n",
    "            self.rf_model = Model(model_type='rf', rf_params=rf_params)\n",
    "        else: \n",
    "            self.models = models\n",
    "        if model_weights is None: \n",
    "            self.model_weights = np.array([0.25, 0.25, 0.25, 0.25])\n",
    "        else: \n",
    "            self.model_weights = model_weights\n",
    "\n",
    "\n",
    "    def fit(self, X_train, y_train, X_val, y_val):\n",
    "        X_train_scaled, X_val_scaled = scale_data(X_train, X_val)\n",
    "\n",
    "        self.xgb_model.fit(X_train, y_train)\n",
    "        self.gnb_model.fit(X_train, y_train)\n",
    "        self.nn_model.fit(X_train_scaled, y_train, X_val=X_val_scaled, y_val=y_val, verbose=0)\n",
    "        self.rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    def predict(self, X_pred, weights=None, mean_type='arithmetic') -> Tuple[np.ndarray, np.ndarray]:\n",
    "        _, X_pred_scaled = scale_data(X_pred, X_pred)\n",
    "        model_predictions = [\n",
    "            self.xgb_model.predict(X_pred)[1], \n",
    "            self.gnb_model.predict(X_pred)[1], \n",
    "            self.nn_model.predict(X_pred_scaled)[1], \n",
    "            self.rf_model.predict(X_pred)[1]\n",
    "        ]\n",
    "        weights = self.model_weights if weights is None else weights\n",
    "        return soft_voting(\n",
    "            list_X_preds=model_predictions, weights=weights, mean_type=mean_type\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING ITERATION 1\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Accuracy: 0.699000 | Logloss: 0.705590 \n",
      "\n",
      "RUNNING ITERATION 2\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step\n",
      "Accuracy: 0.568081 | Logloss: 0.957822 \n",
      "\n",
      "RUNNING ITERATION 3\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step\n",
      "Accuracy: 0.531032 | Logloss: 0.902228 \n",
      "\n",
      "RUNNING ITERATION 4\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step\n",
      "Accuracy: 0.516635 | Logloss: 1.020847 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "simulation_2_results = {}\n",
    "\n",
    "for data_key in data: \n",
    "    print(f\"RUNNING ITERATION {data_key}\") \n",
    "    _X_train, _X_val, _y_train, _y_val = data[data_key]\n",
    "    ensemble = Ensemble(model_weights=simulation_results[data_key][1]['weights'])\n",
    "    ensemble.fit(_X_train, _y_train, _X_val, _y_val)\n",
    "    \n",
    "    _y_val_pred, _y_val_proba = ensemble.predict(_X_val)\n",
    "    accuracy = accuracy_score(_y_val, _y_val_pred)\n",
    "    logloss = log_loss(_y_val, _y_val_proba)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.6f} | Logloss: {logloss:.6f} \\n\")\n",
    "    simulation_2_results[data_key] = {'accuracy': accuracy, 'logloss': logloss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.23), np.float64(0.23), np.float64(0.27), np.float64(0.27))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_key = 1\n",
    "simulation_results[data_key][1]['weights']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import X_train as X \n",
    "from data import y_train as y\n",
    "\n",
    "from tools import train_kcv, create_splits\n",
    "from ensemble import Ensemble, train_ensemble, show_top_weights\n",
    "from base_models import Model\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from collections import Counter\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Various Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1\n",
      "     Train distribution: Counter({np.int64(2): 1631, np.int64(0): 1262, np.int64(1): 1107})\n",
      "     Validation distribution: Counter({np.int64(2): 408, np.int64(0): 315, np.int64(1): 277})\n",
      "\n",
      "Split 2\n",
      "     Train distribution: Counter({np.int64(0): 946, np.int64(2): 407, np.int64(1): 276})\n",
      "     Validation distribution: Counter({np.int64(2): 1632, np.int64(1): 1108, np.int64(0): 631})\n",
      "\n",
      "Split 3\n",
      "     Train distribution: Counter({np.int64(1): 830, np.int64(2): 407, np.int64(0): 315})\n",
      "     Validation distribution: Counter({np.int64(2): 1632, np.int64(0): 1262, np.int64(1): 554})\n",
      "\n",
      "Split 4\n",
      "     Train distribution: Counter({np.int64(2): 1223, np.int64(0): 315, np.int64(1): 276})\n",
      "     Validation distribution: Counter({np.int64(0): 1262, np.int64(1): 1108, np.int64(2): 816})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Balanced split\n",
    "X_train1, X_val1, y_train1, y_val1 = create_splits(X, y)\n",
    "\n",
    "# 2. More class 0 in train\n",
    "X_train2, X_val2, y_train2, y_val2 = create_splits(X, y, bias_class=0, bias_ratio=0.6)\n",
    "\n",
    "# 3. More class 1 in train\n",
    "X_train3, X_val3, y_train3, y_val3 = create_splits(X, y, bias_class=1, bias_ratio=0.6)\n",
    "\n",
    "# 4. More class 2 in train\n",
    "X_train4, X_val4, y_train4, y_val4 = create_splits(X, y, bias_class=2, bias_ratio=0.6)\n",
    "\n",
    "# Print class distributions\n",
    "for i, (y_tr, y_v) in enumerate([(y_train1, y_val1), (y_train2, y_val2), (y_train3, y_val3), (y_train4, y_val4)], 1):\n",
    "    print(f\"Split {i}\\n     Train distribution: {Counter(y_tr)}\\n     Validation distribution: {Counter(y_v)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    1: (X_train1, X_val1, y_train1, y_val1),\n",
    "    2: (X_train2, X_val2, y_train2, y_val2),\n",
    "    3: (X_train3, X_val3, y_train3, y_val3),\n",
    "    4: (X_train4, X_val4, y_train4, y_val4)\n",
    "}\n",
    "\n",
    "with open('params_xgb.json', 'r') as file:\n",
    "    xgb_params = json.load(file)\n",
    "with open('params_rf.json', 'r') as file: \n",
    "    rf_params = json.load(file)\n",
    "xgb_selected_features = ['x4', 'x8', 'x9', 'x10', 'x11']\n",
    "gnb_selected_features = ['x2', 'x3', 'x4', 'x6', 'x8', 'x9', 'x10', 'x11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 13)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1000, 13)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4000,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data[1][0].shape)\n",
    "display(data[1][1].shape)\n",
    "display(data[1][2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the ensemble\n",
    "- For each data distribution, find the best weights for the ensemble learning model\n",
    "- Store and save for next part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING ITERATION 1\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step\n",
      "Model trainings successful, proceeding to weight combination search...\n",
      "Weight combination search done.\n",
      "Top 5 Accuracies:\n",
      "1. Weights: [0.23, 0.23, 0.27, 0.27] | Mean Accuracy: 0.687 | Std Accuracy: 0.005 | Mean Log Loss: 0.715 | Std Log Loss: 0.006\n",
      "2. Weights: [0.2, 0.27, 0.27, 0.27] | Mean Accuracy: 0.687 | Std Accuracy: 0.005 | Mean Log Loss: 0.716 | Std Log Loss: 0.006\n",
      "3. Weights: [0.2, 0.2, 0.3, 0.3] | Mean Accuracy: 0.686 | Std Accuracy: 0.005 | Mean Log Loss: 0.716 | Std Log Loss: 0.007\n",
      "4. Weights: [0.2, 0.23, 0.27, 0.3] | Mean Accuracy: 0.686 | Std Accuracy: 0.005 | Mean Log Loss: 0.717 | Std Log Loss: 0.006\n",
      "5. Weights: [0.17, 0.23, 0.3, 0.3] | Mean Accuracy: 0.685 | Std Accuracy: 0.005 | Mean Log Loss: 0.717 | Std Log Loss: 0.007\n",
      "\n",
      "Bottom 5 Log Losses:\n",
      "1. Weights: [0.23, 0.23, 0.27, 0.27] | Mean Accuracy: 0.687 | Std Accuracy: 0.005 | Mean Log Loss: 0.715 | Std Log Loss: 0.006\n",
      "\n",
      "2. Weights: [0.2, 0.2, 0.3, 0.3] | Mean Accuracy: 0.686 | Std Accuracy: 0.005 | Mean Log Loss: 0.716 | Std Log Loss: 0.007\n",
      "\n",
      "3. Weights: [0.2, 0.27, 0.27, 0.27] | Mean Accuracy: 0.687 | Std Accuracy: 0.005 | Mean Log Loss: 0.716 | Std Log Loss: 0.006\n",
      "\n",
      "4. Weights: [0.2, 0.23, 0.27, 0.3] | Mean Accuracy: 0.686 | Std Accuracy: 0.005 | Mean Log Loss: 0.717 | Std Log Loss: 0.006\n",
      "\n",
      "5. Weights: [0.23, 0.23, 0.23, 0.3] | Mean Accuracy: 0.685 | Std Accuracy: 0.005 | Mean Log Loss: 0.717 | Std Log Loss: 0.005\n",
      "\n",
      "\n",
      "RUNNING ITERATION 2\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Model trainings successful, proceeding to weight combination search...\n",
      "Weight combination search done.\n",
      "Top 5 Accuracies:\n",
      "1. Weights: [0.17, 0.27, 0.27, 0.3] | Mean Accuracy: 0.744 | Std Accuracy: 0.008 | Mean Log Loss: 0.626 | Std Log Loss: 0.011\n",
      "2. Weights: [0.23, 0.23, 0.27, 0.27] | Mean Accuracy: 0.744 | Std Accuracy: 0.008 | Mean Log Loss: 0.623 | Std Log Loss: 0.011\n",
      "3. Weights: [0.17, 0.2, 0.2, 0.43] | Mean Accuracy: 0.744 | Std Accuracy: 0.007 | Mean Log Loss: 0.635 | Std Log Loss: 0.010\n",
      "4. Weights: [0.1, 0.3, 0.3, 0.3] | Mean Accuracy: 0.744 | Std Accuracy: 0.009 | Mean Log Loss: 0.627 | Std Log Loss: 0.012\n",
      "5. Weights: [0.23, 0.23, 0.23, 0.3] | Mean Accuracy: 0.744 | Std Accuracy: 0.008 | Mean Log Loss: 0.626 | Std Log Loss: 0.011\n",
      "\n",
      "Bottom 5 Log Losses:\n",
      "1. Weights: [0.23, 0.23, 0.27, 0.27] | Mean Accuracy: 0.744 | Std Accuracy: 0.008 | Mean Log Loss: 0.623 | Std Log Loss: 0.011\n",
      "\n",
      "2. Weights: [0.2, 0.27, 0.27, 0.27] | Mean Accuracy: 0.743 | Std Accuracy: 0.008 | Mean Log Loss: 0.624 | Std Log Loss: 0.011\n",
      "\n",
      "3. Weights: [0.2, 0.2, 0.3, 0.3] | Mean Accuracy: 0.742 | Std Accuracy: 0.008 | Mean Log Loss: 0.625 | Std Log Loss: 0.012\n",
      "\n",
      "4. Weights: [0.17, 0.23, 0.3, 0.3] | Mean Accuracy: 0.743 | Std Accuracy: 0.007 | Mean Log Loss: 0.625 | Std Log Loss: 0.012\n",
      "\n",
      "5. Weights: [0.2, 0.23, 0.27, 0.3] | Mean Accuracy: 0.744 | Std Accuracy: 0.007 | Mean Log Loss: 0.625 | Std Log Loss: 0.011\n",
      "\n",
      "\n",
      "RUNNING ITERATION 3\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n",
      "Model trainings successful, proceeding to weight combination search...\n",
      "Weight combination search done.\n",
      "Top 5 Accuracies:\n",
      "1. Weights: [0.23, 0.23, 0.27, 0.27] | Mean Accuracy: 0.684 | Std Accuracy: 0.010 | Mean Log Loss: 0.716 | Std Log Loss: 0.011\n",
      "2. Weights: [0.23, 0.23, 0.23, 0.3] | Mean Accuracy: 0.684 | Std Accuracy: 0.011 | Mean Log Loss: 0.719 | Std Log Loss: 0.011\n",
      "3. Weights: [0.17, 0.17, 0.33, 0.33] | Mean Accuracy: 0.683 | Std Accuracy: 0.010 | Mean Log Loss: 0.719 | Std Log Loss: 0.014\n",
      "4. Weights: [0.17, 0.17, 0.3, 0.37] | Mean Accuracy: 0.683 | Std Accuracy: 0.010 | Mean Log Loss: 0.722 | Std Log Loss: 0.013\n",
      "5. Weights: [0.13, 0.13, 0.37, 0.37] | Mean Accuracy: 0.683 | Std Accuracy: 0.010 | Mean Log Loss: 0.721 | Std Log Loss: 0.015\n",
      "\n",
      "Bottom 5 Log Losses:\n",
      "1. Weights: [0.23, 0.23, 0.27, 0.27] | Mean Accuracy: 0.684 | Std Accuracy: 0.010 | Mean Log Loss: 0.716 | Std Log Loss: 0.011\n",
      "\n",
      "2. Weights: [0.2, 0.27, 0.27, 0.27] | Mean Accuracy: 0.680 | Std Accuracy: 0.009 | Mean Log Loss: 0.717 | Std Log Loss: 0.012\n",
      "\n",
      "3. Weights: [0.2, 0.2, 0.3, 0.3] | Mean Accuracy: 0.682 | Std Accuracy: 0.010 | Mean Log Loss: 0.717 | Std Log Loss: 0.012\n",
      "\n",
      "4. Weights: [0.17, 0.23, 0.3, 0.3] | Mean Accuracy: 0.680 | Std Accuracy: 0.010 | Mean Log Loss: 0.718 | Std Log Loss: 0.013\n",
      "\n",
      "5. Weights: [0.2, 0.23, 0.27, 0.3] | Mean Accuracy: 0.681 | Std Accuracy: 0.010 | Mean Log Loss: 0.719 | Std Log Loss: 0.012\n",
      "\n",
      "\n",
      "RUNNING ITERATION 4\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step\n",
      "Model trainings successful, proceeding to weight combination search...\n",
      "Weight combination search done.\n",
      "Top 5 Accuracies:\n",
      "1. Weights: [0.23, 0.23, 0.27, 0.27] | Mean Accuracy: 0.763 | Std Accuracy: 0.008 | Mean Log Loss: 0.593 | Std Log Loss: 0.012\n",
      "2. Weights: [0.23, 0.23, 0.23, 0.3] | Mean Accuracy: 0.763 | Std Accuracy: 0.007 | Mean Log Loss: 0.595 | Std Log Loss: 0.012\n",
      "3. Weights: [0.17, 0.17, 0.33, 0.33] | Mean Accuracy: 0.762 | Std Accuracy: 0.009 | Mean Log Loss: 0.596 | Std Log Loss: 0.014\n",
      "4. Weights: [0.13, 0.13, 0.37, 0.37] | Mean Accuracy: 0.762 | Std Accuracy: 0.008 | Mean Log Loss: 0.598 | Std Log Loss: 0.015\n",
      "5. Weights: [0.2, 0.2, 0.3, 0.3] | Mean Accuracy: 0.762 | Std Accuracy: 0.008 | Mean Log Loss: 0.594 | Std Log Loss: 0.013\n",
      "\n",
      "Bottom 5 Log Losses:\n",
      "1. Weights: [0.23, 0.23, 0.27, 0.27] | Mean Accuracy: 0.763 | Std Accuracy: 0.008 | Mean Log Loss: 0.593 | Std Log Loss: 0.012\n",
      "\n",
      "2. Weights: [0.2, 0.27, 0.27, 0.27] | Mean Accuracy: 0.762 | Std Accuracy: 0.007 | Mean Log Loss: 0.593 | Std Log Loss: 0.012\n",
      "\n",
      "3. Weights: [0.2, 0.2, 0.3, 0.3] | Mean Accuracy: 0.762 | Std Accuracy: 0.008 | Mean Log Loss: 0.594 | Std Log Loss: 0.013\n",
      "\n",
      "4. Weights: [0.2, 0.23, 0.27, 0.3] | Mean Accuracy: 0.761 | Std Accuracy: 0.007 | Mean Log Loss: 0.595 | Std Log Loss: 0.012\n",
      "\n",
      "5. Weights: [0.23, 0.23, 0.23, 0.3] | Mean Accuracy: 0.763 | Std Accuracy: 0.007 | Mean Log Loss: 0.595 | Std Log Loss: 0.012\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CREATE PREDICTIONS\n",
    "simulation_results = {}\n",
    "for data_key in data:\n",
    "    print(f\"RUNNING ITERATION {data_key}\") \n",
    "    _X_train, _X_val, _y_train, _y_val = data[data_key]\n",
    "\n",
    "    _models = [\n",
    "        Model(model_type='xgb', selected_features=xgb_selected_features, xgb_params=xgb_params),\n",
    "        Model(model_type='gnb', selected_features=gnb_selected_features),\n",
    "        Model(model_type='nn', nn_params=X.shape[1]),\n",
    "        Model(model_type='rf', rf_params=rf_params)\n",
    "    ]\n",
    "\n",
    "    _results, _best_result = train_ensemble(\n",
    "        _X_train, _y_train, \n",
    "        models = _models,\n",
    "        k_fold_type = 'shuffle_split',\n",
    "        mean_type = 'arithmetic'\n",
    "    )\n",
    "    show_top_weights(_results)\n",
    "    print()\n",
    "\n",
    "    simulation_results[data_key] = {\n",
    "        'results': _results,\n",
    "        'best_result': _best_result,\n",
    "        'models': _models\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_results = {\n",
    "    key: {k: v for k, v in value.items() if k != \"models\"}\n",
    "    for key, value in simulation_results.items()\n",
    "}\n",
    "with open(\"results_simulation_1.json\", \"w\") as outfile: \n",
    "    json.dump(filtered_results, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Accuracy and Log-Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"results_simulation_1.json\", 'r') as file:\n",
    "#     results = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING ITERATION 1\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Accuracy: 0.700000 | Logloss: 0.699940 \n",
      "\n",
      "RUNNING ITERATION 2\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step\n",
      "Accuracy: 0.566894 | Logloss: 0.957540 \n",
      "\n",
      "RUNNING ITERATION 3\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step\n",
      "Accuracy: 0.531323 | Logloss: 0.899074 \n",
      "\n",
      "RUNNING ITERATION 4\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step\n",
      "Accuracy: 0.532643 | Logloss: 1.012205 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "simulation_2_results = {}\n",
    "\n",
    "for data_key in data: \n",
    "    print(f\"RUNNING ITERATION {data_key}\") \n",
    "    _X_train, _X_val, _y_train, _y_val = data[data_key]\n",
    "    \n",
    "    ensemble = Ensemble(\n",
    "        models=simulation_results[data_key]['models'],\n",
    "        model_weights=simulation_results[data_key]['best_result']['weights']\n",
    "    )\n",
    "    ensemble.fit(_X_train, _y_train, _X_val, _y_val)\n",
    "    \n",
    "    _y_val_pred, _y_val_proba = ensemble.predict(_X_val)\n",
    "    accuracy = accuracy_score(_y_val, _y_val_pred)\n",
    "    logloss = log_loss(_y_val, _y_val_proba)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.6f} | Logloss: {logloss:.6f} \\n\")\n",
    "    simulation_2_results[data_key] = {'accuracy': accuracy, 'logloss': logloss}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SUTD\\KTH\\DD2421 Machine Learning\\DD2421-programming-challenge\\tools.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[bool_cols] = X_train[bool_cols].astype(int)\n",
      "c:\\SUTD\\KTH\\DD2421 Machine Learning\\DD2421-programming-challenge\\tools.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = le.fit_transform(X_train[col])\n"
     ]
    }
   ],
   "source": [
    "from tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model CV Accuracy: 0.6848 ± 0.0139\n",
      "Submission file saved as submission_ensemble.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assume train_raw and test_raw are pre-loaded DataFrames\n",
    "\n",
    "# Define features and target\n",
    "features = [f\"x{i}\" for i in range(1, 14)]\n",
    "X_train = train_raw[features].copy()\n",
    "y_train = train_raw['y'].copy()\n",
    "X_test = test_raw[features].copy()  # Test set (10,000 datapoints for Kaggle)\n",
    "\n",
    "# Encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Preprocessing: Convert booleans to integers\n",
    "bool_cols = X_train.select_dtypes(include=['bool']).columns\n",
    "X_train[bool_cols] = X_train[bool_cols].astype(int)\n",
    "X_test[bool_cols] = X_test[bool_cols].astype(int)\n",
    "\n",
    "# Preprocessing: Encode categorical features (if any)\n",
    "cat_cols = X_train.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    X_train[col] = le.fit_transform(X_train[col])\n",
    "    X_test[col] = le.transform(X_test[col])\n",
    "\n",
    "# Define individual models\n",
    "xgb_model = XGBClassifier(\n",
    "    objective='multi:softprob',  # For multiclass probability output\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    n_estimators=300,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "gnb_model = GaussianNB()\n",
    "\n",
    "# Create ensemble VotingClassifier with equal weights\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[('xgb', xgb_model), ('gnb', gnb_model)],\n",
    "    voting='soft',    # Use probabilities to average predictions\n",
    "    weights=[1, 1]\n",
    ")\n",
    "\n",
    "# Evaluate the ensemble with 5-fold Stratified Cross-Validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "\n",
    "for train_idx, val_idx in kf.split(X_train, y_train_encoded):\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_train_encoded[train_idx], y_train_encoded[val_idx]\n",
    "    \n",
    "    ensemble_model.fit(X_tr, y_tr)\n",
    "    y_val_pred = ensemble_model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    cv_scores.append(acc)\n",
    "\n",
    "print(f\"Ensemble Model CV Accuracy: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\")\n",
    "\n",
    "# Train the final ensemble model on the full training set\n",
    "ensemble_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Predict on the test set and convert predictions back to original labels\n",
    "y_test_pred = ensemble_model.predict(X_test)\n",
    "y_test_pred_labels = label_encoder.inverse_transform(y_test_pred)\n",
    "\n",
    "# Save predictions for Kaggle submission\n",
    "submission = pd.DataFrame({\"id\": X_test.index, \"y\": y_test_pred_labels})\n",
    "submission.to_csv(\"submission_ensemble.csv\", index=False)\n",
    "print(\"Submission file saved as submission_ensemble.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
